{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_utils.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from utils import *"
      ],
      "metadata": {
        "id": "ltwRQZUi2FJJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the topics from the model for a given new document\n",
        "def test_model(input, model):\n",
        "  # cleanand preprocess the input text\n",
        "  if(type(input) != list):\n",
        "    input = input.split()\n",
        "  data_c = Data_Cleaning(input)\n",
        "  clean_txt = data_c.clean_dataset()\n",
        "  data_pro = Data_Preprocessing(clean_txt)\n",
        "  lem_txt, dictt, corrpus = data_pro.preprocessing_dataset()\n",
        "\n",
        "#get the model predicted topics with their probabilities\n",
        "  doc_topics = model[corrpus[0]]\n",
        "  return doc_topics"
      ],
      "metadata": {
        "id": "Zjd80zV_3S0g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to return the the most relevant 3 topics for a given text\n",
        "def get_top_3_topics(doc_topics):\n",
        "  top_topics = []\n",
        "  for i in range(3):\n",
        "    maxx = max(doc_topics[0],key=lambda item:item[1])\n",
        "    doc_topics[0].remove(maxx)\n",
        "    top_topics.append((maxx))\n",
        "\n",
        "  return top_topics"
      ],
      "metadata": {
        "id": "gozDAMif3ktl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OamZXIIY0vVh"
      },
      "outputs": [],
      "source": [
        "# print most fit 3 topics\n",
        "def print_top_topics(_3_topics, all_topics):\n",
        "  for j in range(3):\n",
        "    for i in all_topics:\n",
        "      if(_3_topics[j][0] == i[0]):\n",
        "        print(\"topic nuber: \", j+1, \" with index: \",  int(_3_topics[j][0])+1, \" and probability: \", _3_topics[j][1], \" is: \", i[1])\n",
        "  print(\"=============================================================================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## assign 3 topics for each document in the given dataset\n",
        "def test_string(text, model, all_topics):\n",
        "  test_topics = test_model(text, model)\n",
        "  _3_topics = get_top_3_topics(test_topics)\n",
        "  print_top_topics(_3_topics, all_topics)\n",
        "  return _3_topics"
      ],
      "metadata": {
        "id": "WhYZayY907sl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(text, model, all_topics):\n",
        "  if(type(text) == list):\n",
        "    for i in text:\n",
        "      _3_topics = test_string(i, model, all_topics)\n",
        "  else:\n",
        "    _3_topics = test_string(text, model, all_topics)"
      ],
      "metadata": {
        "id": "-zcdyV7I1cXA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DYbvhaqe2j2M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}