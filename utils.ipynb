{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyLDAvis"
      ],
      "metadata": {
        "id": "DRPO64iaIA0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNrI-k4U7dug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d28ccb-da7f-4e51-865b-a00709ad8d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ],
      "source": [
        "from wordcloud import WordCloud\n",
        "import gensim\n",
        "from gensim.models import CoherenceModel\n",
        "import pickle\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lemqIMG8Aqs5",
        "outputId": "3e2566db-45cc-4b8c-b5ad-dc89763b8e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting import-ipynb\n",
            "  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=605654cee988ee1b28f5e215f128c77e905e2cd5e7b6b01bd8d17a041bd1ec4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data_cleaning import Data_Cleaning\n",
        "from data_preprocessing import Data_Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMwmLznXDICS",
        "outputId": "7db60508-8c63-4a73-a29f-f9ce22d0d955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from data_cleaning.ipynb\n",
            "importing Jupyter notebook from data_preprocessing.ipynb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "<string>:16: DeprecationWarning: invalid escape sequence \\s\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/decorators.py:70: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
            "  formatvalue=lambda value: \"\")[1:-1]\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from .mio5_utils import VarReader5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the lda models\n",
        "def run_lda_model(dictt, corp, num_top, ran_st, up_every, ch_size, pas):\n",
        "  model = gensim.models.ldamodel.LdaModel(corpus=corp,\n",
        "                                           id2word=dictt,\n",
        "                                           num_topics=num_top,\n",
        "                                           random_state=ran_st,\n",
        "                                           update_every=up_every,\n",
        "                                           chunksize=ch_size,\n",
        "                                           passes=pas,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "  return model"
      ],
      "metadata": {
        "id": "UfGLy0qL2J9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the most common 1000 word in the given dataset\n",
        "def get_most_common_words(texts):\n",
        "  text = \"\"\n",
        "  for txt in texts:\n",
        "    text += txt\n",
        "\n",
        "  wordcloud = WordCloud(background_color=\"black\", max_words=1000, contour_width=5, contour_color='steelblue')\n",
        "  wordcloud.generate(text)\n",
        "  return wordcloud.to_image()"
      ],
      "metadata": {
        "id": "Al7J-Mot7gfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return the topic from model in a format of topic_index, topic_string\n",
        "# in this case it is more easier to read the topics\n",
        "# topic is 10 words\n",
        "def show_model_topics(model):\n",
        "  topics = []\n",
        "  for topic_id in range(model.num_topics):\n",
        "    topic = model.show_topic(topic_id, 10)\n",
        "    topic_words = [ w for w, _ in topic ]\n",
        "    print('{}: {}'.format(topic_id, ' '.join(topic_words)))\n",
        "    topics.append((topic_id, ' '.join(topic_words)))\n",
        "  return topics"
      ],
      "metadata": {
        "id": "qq1kshazgPVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_-gxfXz6Flfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# measure the model performance using perplexity metric\n",
        "# the lower perplexity the better model\n",
        "def compute_perplexity(model, corpus):\n",
        "  model_perplexity = model.log_perplexity(corpus)\n",
        "  return model_perplexity"
      ],
      "metadata": {
        "id": "yP337ozK7pg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measure the model performance using coherence score\n",
        "#the higher the better\n",
        "def computer_coherence_score(model, lemmtize_text, dictionary, coherence='c_v'):\n",
        "  coherence_model = CoherenceModel(model=model, texts=lemmtize_text, dictionary=dictionary, coherence=coherence)\n",
        "  coherence_score = coherence_model.get_coherence()\n",
        "  return coherence_score"
      ],
      "metadata": {
        "id": "jyei7lMrF1hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the lda model\n",
        "def save_model(model, file_name):\n",
        "  pickle.dump(model, open(file_name, 'wb'))\n",
        "  print(\"Model saved...\")\n",
        "  return"
      ],
      "metadata": {
        "id": "hrPAl-5UGwCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load lda model \n",
        "def load_model(file_name):\n",
        "  model = pickle.load(open(file_name, 'rb'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "P2WIarLjMCnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize topics\n",
        "def visualize_topics(model, dictionary, corpus):\n",
        "  pyLDAvis.enable_notebook()\n",
        "  vis = pyLDAvis.gensim_models.prepare(model, corpus, dictionary)\n",
        "  return vis"
      ],
      "metadata": {
        "id": "b1BrPCmVAvat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to retrive the best topics number based on models coherence scores\n",
        "def get_optimal_topics_num(scores):\n",
        "  max_value =max(scores)\n",
        "  indx = scores.index(max_value)\n",
        "  return max_value, indx"
      ],
      "metadata": {
        "id": "BsZg8A1XAOm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a graph to visualize the number of topics for each tried model\n",
        "def plot_num_topics(scores, indx, x):\n",
        "  col =[] # hold different color to make highest point with unique color\n",
        "  for i in range(len(x)):\n",
        "    if (i== indx):\n",
        "      col.append('red')\n",
        "    else:\n",
        "      col.append('blue')\n",
        "\n",
        "  plt.plot(x, scores, c=\"black\")\n",
        "  for i in range(len(x)):\n",
        "    plt.scatter(x[i], scores[i], c = col[i], s = 10,\n",
        "          linewidth = 5)\n",
        "  \n",
        "  plt.xlabel('number of topics')\n",
        "  plt.ylabel('coherence score')\n",
        "  plt.title('optimal # topics')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8vTENA6IHyaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train different models with hyperparamtr tuning and calculate their coherence scores to get the best model among.\n",
        "def compute_coherence_scores(dictionary, corpus, lemma_text, limit, start=2, step=1):\n",
        "  x = x = range(start, limit, step)\n",
        "  coherence_scores = []\n",
        "  models = []\n",
        "  for num_topics in range(start, limit, step):\n",
        "      model = run_lda_model(dictionary, corpus, num_topics, 24, 1, 500, 15)\n",
        "      models.append(model)\n",
        "      coherence_score = computer_coherence_score(model, lemma_text, dictionary, 'c_v')\n",
        "      coherence_scores.append(coherence_score)\n",
        "\n",
        "  return models, coherence_scores, x"
      ],
      "metadata": {
        "id": "BJ5XaIlILFcx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}